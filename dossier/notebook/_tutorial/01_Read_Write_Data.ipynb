{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"_media/logo_stellantis.png\" width=\"300\">\n",
    "\n",
    "<font size=\"+3\"><b><center>Tutorial 01: Read & Write data</center></b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how to read & write data in HDFS or Oracle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from app_template.configuration import spark_config\n",
    "from app_template.utils import system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context, spark_session = spark_config.get_spark(\n",
    "    app_name=\"[app00] Test_Read_Write_Data\",\n",
    "    driver_cores=1,\n",
    "    driver_mem=\"4g\",\n",
    "    max_executors=8,\n",
    "    executor_cores=4,\n",
    "    executor_mem=\"4g\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filepath\n",
    "flow_filepath = \"/user/brc05/data/refined/manf001_vehc_prdc_flow/year=2021/month=02/day=05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read & filter data from HDFS\n",
    "df_flow = (\n",
    "    spark_session.read.parquet(flow_filepath)\n",
    "    .filter(\n",
    "        (F.col(\"site_code\") == \"PY\")\n",
    "        & (F.col(\"genr_door\") == \"SMON\")\n",
    "    )\n",
    "    .select(\"vin\", \"faml_grp_labl\", \"pass_date\")\n",
    "    .orderBy(\"pass_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[vin: string, faml_grp_labl: string, pass_date: timestamp]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vin</th>\n",
       "      <th>faml_grp_labl</th>\n",
       "      <th>pass_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VR1UJZKXZMW005254</td>\n",
       "      <td>e-D34</td>\n",
       "      <td>2021-02-05 04:56:51.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VR1UCYHZSMW003839</td>\n",
       "      <td>t-D34</td>\n",
       "      <td>2021-02-05 05:36:02.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VXKUSHNSSMW003288</td>\n",
       "      <td>P2QO-TH</td>\n",
       "      <td>2021-02-05 06:06:23.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VXKUSHNSSMW003348</td>\n",
       "      <td>P2QO-TH</td>\n",
       "      <td>2021-02-05 06:08:21.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VXKUSHNSSMW003350</td>\n",
       "      <td>P2QO-TH</td>\n",
       "      <td>2021-02-05 06:09:44.501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 vin faml_grp_labl               pass_date\n",
       "0  VR1UJZKXZMW005254         e-D34 2021-02-05 04:56:51.155\n",
       "1  VR1UCYHZSMW003839         t-D34 2021-02-05 05:36:02.575\n",
       "2  VXKUSHNSSMW003288       P2QO-TH 2021-02-05 06:06:23.077\n",
       "3  VXKUSHNSSMW003348       P2QO-TH 2021-02-05 06:08:21.313\n",
       "4  VXKUSHNSSMW003350       P2QO-TH 2021-02-05 06:09:44.501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/user/u542310/brc14/app00/data/prod_flow'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output dirpath\n",
    "output_dirpath = system.get_hdfs_path(os.path.join(os.environ[\"UNXDATA\"], \"prod_flow\"))\n",
    "output_dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to HDFS\n",
    "df_flow.coalesce(1).write.parquet(output_dirpath, \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure you have created the *application.yml* file in the *conf* directory and filled in the *brcdb* section (see this [section](https://github.psa-cloud.com/brc14/app00#user-specific-settings) of the *README* for more information)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate OracleDatabase object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app_template.infra.oracle_database import OracleDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_db = OracleDatabase(dialect=\"jdbc\", spark_session=spark_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The default connector is 'jdbc'. It allows you to perform parallelized read/write. You can also choose 'cx_oracle' connector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SQL query\n",
    "query = \"\"\"\n",
    "(\n",
    "    SELECT vin, faml_grp_labl, pass_date\n",
    "    FROM BRC05.MANF001_VEHC_PRDC_FLOW\n",
    "    WHERE SITE_CODE = 'PY'\n",
    "    AND PASS_DATE >= to_date('05/02/21', 'dd/mm/yy')\n",
    "    AND PASS_DATE < to_date('06/02/21', 'dd/mm/yy')\n",
    "    AND GENR_DOOR = 'SMON'\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from Oracle\n",
    "df_flow = oracle_db.read_df_from_query(query, fetchsize=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[VIN: string, FAML_GRP_LABL: string, PASS_DATE: timestamp]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIN</th>\n",
       "      <th>FAML_GRP_LABL</th>\n",
       "      <th>PASS_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VXKUSHNEKMW003477</td>\n",
       "      <td>P2QO-TH</td>\n",
       "      <td>2021-02-05 08:01:17.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VR1URHNJNMW005304</td>\n",
       "      <td>t-D34</td>\n",
       "      <td>2021-02-05 08:25:50.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VXKUSHNSSMW003749</td>\n",
       "      <td>P2QO-TH</td>\n",
       "      <td>2021-02-05 10:03:41.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VR1UCYHZSMW003839</td>\n",
       "      <td>t-D34</td>\n",
       "      <td>2021-02-05 05:36:02.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VXKUSHNSSMW003695</td>\n",
       "      <td>P2QO-TH</td>\n",
       "      <td>2021-02-05 07:35:16.423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 VIN FAML_GRP_LABL               PASS_DATE\n",
       "0  VXKUSHNEKMW003477       P2QO-TH 2021-02-05 08:01:17.943\n",
       "1  VR1URHNJNMW005304         t-D34 2021-02-05 08:25:50.448\n",
       "2  VXKUSHNSSMW003749       P2QO-TH 2021-02-05 10:03:41.672\n",
       "3  VR1UCYHZSMW003839         t-D34 2021-02-05 05:36:02.575\n",
       "4  VXKUSHNSSMW003695       P2QO-TH 2021-02-05 07:35:16.423"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- The *fetchsize* parameter is set by default to 20000 in the OracleDatabase class (default Oracle row fetch size value is 10). It represents the number of rows to load per network call.\n",
    "- You can also partition the reading by using the parameters *partition_column*, *lower_bound*, *upper_bound* (see doc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to Oracle\n",
    "oracle_db.write_df_to_oracle(\n",
    "    df_flow,\n",
    "    \"app00_prod_flow_tutorial\",\n",
    "    mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: *mode* parameter defines how to behave if the table already exists: 'append', 'overwrite', 'error'."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
